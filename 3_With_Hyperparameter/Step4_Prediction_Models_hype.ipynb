{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 1st\n",
    "\n",
    "#import methods and datas in Predction Models with relevant objects\n",
    "%run ./Step3_Classifier_V10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 2nd\n",
    "#model_hype is a version of model 5 with hyperparameters for length and counts of max_stems\n",
    "#as magnitude of effect of length (of max_stems) and count in (0,1) interval, \n",
    "#alpha and beta are chosen given that fact as a hyperparameter increases, \n",
    "#so contribution of relevant parameter (length for alpha, count for beta) into the prediction decreases.\n",
    "#in case of alpha=beta, model is equivalent to predict_model5 \n",
    "#in case of alpha=0, model is equivalent to predict_model2 \n",
    "#in case of beta=0, model is based on category of max_stems having the longest length in doc  \n",
    "\n",
    "\n",
    "def predict_model_hype1(doc,train_X,train_y,alpha,beta):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not, alpha and beta must be non-negative because relevant bases may be 0\n",
    "    if len(outcome)==0 or alpha<0 or beta<0 :\n",
    "        return \"No Prediction\"\n",
    "    \n",
    "    #score (in direct proportion to both length and counts of max_stems) list \n",
    "    scores=[[],[],[],[]]\n",
    "    #list of maximum of score for each categories\n",
    "    max_score_list=[0]*4\n",
    "    length_list=[]\n",
    "    for j in range(0,len(outcome)):\n",
    "        length_list.append(outcome[j][1])\n",
    "        \n",
    "    #get sum of max_length in doc \n",
    "    sum_length=sum(length_list)\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #value1, length of max_stems\n",
    "            #with alpha exponantial contribution\n",
    "            value1=(outcome[j][1]/sum_length)**alpha\n",
    "            #value2, count of categories weighted by total of counts (of categories) in train set\n",
    "            #with beta exponantial contribution\n",
    "            value2=(outcome[j][2][i]/train_counts[i])**beta\n",
    "            #value3, a score in direct proportion to both length and counts of max_stems\n",
    "            value3=value1*value2\n",
    "            #append rounded value3\n",
    "            scores[i].append(value3)\n",
    "        \n",
    "        #set maximum score for each categories\n",
    "        max_score_list[i]=max(scores[i])\n",
    "        #print(max_score_list[i])\n",
    "    \n",
    "      \n",
    "    # get category with maximum scores in all max_stems in doc\n",
    "    return main_categories[max_score_list.index(max(max_score_list))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model_hype1(doc):\n",
    "    return predict_model_hype1(doc,X_train,y_train,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 3rd\n",
    "#model_hype is a version of model 5 with hyperparameters for length and counts of max_stems\n",
    "#as magnitude of effect of length (of max_stems) and count in (0,1) interval, \n",
    "#alpha and beta are chosen given that fact as a hyperparameter increases, \n",
    "#so contribution of relevant parameter (length for alpha, count for beta) into the prediction decreases.\n",
    "#in case of alpha=beta, model is equivalent to predict_model5 \n",
    "#in case of alpha=0, model is equivalent to predict_model2 \n",
    "#in case of beta=0, model is based on category of max_stems having the longest length in doc  \n",
    "\n",
    "\n",
    "def predict_model_hype2(doc,train_X,train_y,alpha,beta):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not, alpha and beta must be non-negative because relevant bases may be 0\n",
    "    if len(outcome)==0 or alpha<0 or beta<0 :\n",
    "        return \"No Prediction\"\n",
    "    \n",
    "    #score (in direct proportion to both length and counts of max_stems) list \n",
    "    scores=[0]*4\n",
    "    #list of maximum of score for each categories\n",
    "    max_score_list=[0]*4\n",
    "    length_list=[]\n",
    "    for j in range(0,len(outcome)):\n",
    "        length_list.append(outcome[j][1])\n",
    "        \n",
    "    #get sum of max_length in doc \n",
    "    sum_length=sum(length_list)\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #value1, length of max_stems\n",
    "            #with alpha exponantial contribution\n",
    "            value1=(outcome[j][1]/sum_length)**alpha\n",
    "            #value2, count of categories weighted by total of counts (of categories) in train set\n",
    "            #with beta exponantial contribution\n",
    "            value2=(outcome[j][2][i]/train_counts[i])**beta\n",
    "            #value3, a score in direct proportion to both length and counts of max_stems\n",
    "            value3=value1*value2\n",
    "            #append rounded value3\n",
    "            scores[i]=scores[i]+value3\n",
    "       \n",
    "      \n",
    "    # get category with maximum scores in all max_stems in doc\n",
    "    return main_categories[scores.index(max(scores))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model_hype2(doc):\n",
    "    return predict_model_hype(doc,X_train,y_train,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 4th\n",
    "#model_hype is a version of model 5 with hyperparameters for length and counts of max_stems\n",
    "#as magnitude of effect of length (of max_stems) and count in (0,1) interval, \n",
    "#alpha and beta are chosen given that fact as a hyperparameter increases, \n",
    "#so contribution of relevant parameter (length for alpha, count for beta) into the prediction decreases.\n",
    "#in case of alpha=beta, model is equivalent to predict_model5 \n",
    "#in case of alpha=0, model is equivalent to predict_model2 \n",
    "#in case of beta=0, model is based on category of max_stems having the longest length in doc  \n",
    "\n",
    "\n",
    "def predict_model_hype3(doc,train_X,train_y,alpha,beta):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not, alpha and beta must be non-negative because relevant bases may be 0\n",
    "    if len(outcome)==0 or alpha<0 or beta<0 :\n",
    "        return \"No Prediction\"\n",
    "    \n",
    "    #score (in direct proportion to both length and counts of max_stems) list \n",
    "    scores=[0]*4\n",
    "    #list of maximum of score for each categories\n",
    "    max_score_list=[0]*4\n",
    "    length_list=[]\n",
    "    for j in range(0,len(outcome)):\n",
    "        length_list.append(outcome[j][1])\n",
    "        \n",
    "    #get sum of max_length in doc \n",
    "    sum_length=sum(length_list)\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #value1, length of max_stems\n",
    "            #with alpha exponantial contribution\n",
    "            value1=(outcome[j][1]/sum_length)**alpha\n",
    "            #value2, count of categories weighted by total of counts (of categories) in train set\n",
    "            #with beta exponantial contribution\n",
    "            value2=(outcome[j][2][i]/train_counts[i])**beta\n",
    "            #value3, a score in direct proportion to both length and counts of max_stems\n",
    "            value3=value1*value2\n",
    "            #append rounded value3\n",
    "            scores[i]=scores[i]+value3\n",
    "       \n",
    "    scores=[scores/train_counts for scores,train_counts in zip(scores,train_counts)]  \n",
    "    # get category with maximum scores in all max_stems in doc\n",
    "    return main_categories[scores.index(max(scores))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model_hype3(doc):\n",
    "    return predict_model_hype3(doc,X_train,y_train,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________hype1________________\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "_________________hype2________________\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "_________________hype3________________\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n",
      "Teknoloji\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['atina', 5, [3, 0, 0, 0], [1.0, 0.0, 0.0, 0.0], 'DÜNYA', 'No Prediction'],\n",
       " ['sputnik', 7, [7, 0, 0, 0], [1.0, 0.0, 0.0, 0.0], 'DÜNYA', 'No Prediction'],\n",
       " ['çalışan', 7, [60, 1, 0, 1], [0.97, 0.02, 0.0, 0.02], 'DÜNYA', 'SPOR'],\n",
       " ['muhabir', 7, [8, 3, 0, 0], [0.73, 0.27, 0.0, 0.0], 'DÜNYA', 'SPOR'],\n",
       " ['saldırı', 7, [253, 3, 1, 1], [0.98, 0.01, 0.0, 0.0], 'DÜNYA', 'SPOR'],\n",
       " ['foto', 4, [47, 5, 6, 2], [0.78, 0.08, 0.1, 0.03], 'DÜNYA', 'SANAT'],\n",
       " ['makine', 6, [8, 0, 0, 0], [1.0, 0.0, 0.0, 0.0], 'DÜNYA', 'No Prediction'],\n",
       " ['elinden', 7, [6, 1, 2, 0], [0.67, 0.11, 0.22, 0.0], 'DÜNYA', 'SANAT'],\n",
       " ['alındı', 6, [58, 5, 2, 1], [0.88, 0.08, 0.03, 0.02], 'DÜNYA', 'SPOR']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "n=random.randint(1,train_count)\n",
    "#print(n)\n",
    "#doc=X_train[X_train.index[n]]\n",
    "42308\n",
    "doc=X_test[42308]\n",
    "print(\"_________________hype1________________\")\n",
    "print(predict_model_hype1(doc,X_train,y_train,0,1))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.1,0.9))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.2,0.8))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.3,0.7))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.4,0.6))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.5,0.5))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.6,0.4))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.7,0.3))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.8,0.2))\n",
    "print(predict_model_hype1(doc,X_train,y_train,0.9,0.1))\n",
    "print(predict_model_hype1(doc,X_train,y_train,1,0))\n",
    "\n",
    "print(\"_________________hype2________________\")\n",
    "print(predict_model_hype2(doc,X_train,y_train,0,1))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.1,0.9))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.2,0.8))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.3,0.7))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.4,0.6))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.5,0.5))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.6,0.4))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.7,0.3))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.8,0.2))\n",
    "print(predict_model_hype2(doc,X_train,y_train,0.9,0.1))\n",
    "print(predict_model_hype2(doc,X_train,y_train,1,0))\n",
    "\n",
    "print(\"_________________hype3________________\")\n",
    "print(predict_model_hype3(doc,X_train,y_train,0,1))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.1,0.9))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.2,0.8))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.3,0.7))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.4,0.6))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.5,0.5))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.6,0.4))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.7,0.3))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.8,0.2))\n",
    "print(predict_model_hype3(doc,X_train,y_train,0.9,0.1))\n",
    "print(predict_model_hype3(doc,X_train,y_train,1,0))\n",
    "\n",
    "analyze_doc(doc,X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 3rd\n",
    "#hype_list consists of pairs in list [alpha, beta]\n",
    "def Integrated_model_hype1(doc,train_X,train_y,hype_list):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    m=len(hype_list)\n",
    "    #check whether outcome is empty, or not, alpha and beta must be non-negative because relevant bases may be 0\n",
    "    if len(outcome)==0 :\n",
    "        return [\"No Prediction\"]*m\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #list of maximum of score for each categories\n",
    "    max_score_list=[0]*4\n",
    "    length_list=[]\n",
    "    for j in range(0,len(outcome)):\n",
    "        length_list.append(outcome[j][1])\n",
    "        \n",
    "    \n",
    "    #get sum of max_length in doc \n",
    "    sum_length=sum(length_list)\n",
    "    result_list=[] \n",
    "    for k in range(0,m):\n",
    "        \n",
    "        #check element of list is paired list ?\n",
    "        if len(hype_list[k]) !=2:\n",
    "            result_list.append(\"No Prediction (dimension error)\")\n",
    "        elif hype_list[k][0]<0 or hype_list[k][1]<0:\n",
    "            result_list.append(\"No Prediction (range error)\")\n",
    "        else:\n",
    "            #iterator for categories\n",
    "            for i in range(0,4):\n",
    "                #score (in direct proportion to both length and counts of max_stems) list \n",
    "                scores=[[],[],[],[]]\n",
    "            #iterator for max_stems of doc\n",
    "                for j in range(0,len(outcome)):\n",
    "                    #value1, length of max_stems\n",
    "                    #with alpha exponantial contribution\n",
    "                    alpha=hype_list[k][0]\n",
    "                    value1=(outcome[j][1]/sum_length)**alpha\n",
    "                    #value2, count of categories weighted by total of counts (of categories) in train set\n",
    "                    #with beta exponantial contribution\n",
    "                    beta=hype_list[k][1]\n",
    "                    value2=(outcome[j][2][i]/train_counts[i])**beta\n",
    "                    #value3, a score in direct proportion to both length and counts of max_stems\n",
    "                    value3=value1*value2\n",
    "                    #append rounded value3\n",
    "                    scores[i].append(value3)\n",
    "        \n",
    "                #set maximum score for each categories   \n",
    "                max_score_list[i]=max(scores[i])\n",
    "                #print(max_score_list[i])\n",
    "            #append the result\n",
    "            result_list.append(main_categories[max_score_list.index(max(max_score_list))])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "   \n",
    "    return result_list\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_Integrated_hype1(doc):\n",
    "    return Integrated_model_hype1(doc,train_X,train_y,hype_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
