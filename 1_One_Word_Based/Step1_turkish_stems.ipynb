{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>derivates</th>\n",
       "      <th>stems</th>\n",
       "      <th>structure</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>çöğürü</td>\n",
       "      <td>çöğür</td>\n",
       "      <td>Noun+A3sg+P3sg+Nom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>çöğüründen</td>\n",
       "      <td>çöğür</td>\n",
       "      <td>Noun+A3sg+P3sg+Abl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>çöğür</td>\n",
       "      <td>çöğür</td>\n",
       "      <td>Noun+A3sg+Pnon+Nom</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>çöğürcü</td>\n",
       "      <td>çöğürcü</td>\n",
       "      <td>Noun+A3sg+Pnon+Nom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>çöğürden</td>\n",
       "      <td>çöğür</td>\n",
       "      <td>Noun+A3sg+Pnon+Abl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337893</td>\n",
       "      <td>zurnaya</td>\n",
       "      <td>zurna</td>\n",
       "      <td>Noun+A3sg+Pnon+Dat</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337894</td>\n",
       "      <td>zurnayla</td>\n",
       "      <td>zurna</td>\n",
       "      <td>Noun+A3sg+Pnon+Ins</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337895</td>\n",
       "      <td>zurnazen</td>\n",
       "      <td>zurnazen</td>\n",
       "      <td>Noun+A3sg+Pnon+Nom</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337896</td>\n",
       "      <td>zurnazenler</td>\n",
       "      <td>zurnazen</td>\n",
       "      <td>Noun+A3pl+Pnon+Nom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337897</td>\n",
       "      <td>zurt</td>\n",
       "      <td>zurt</td>\n",
       "      <td>dup</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1337898 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           derivates     stems           structure  frequency\n",
       "0             çöğürü     çöğür  Noun+A3sg+P3sg+Nom          1\n",
       "1         çöğüründen     çöğür  Noun+A3sg+P3sg+Abl          2\n",
       "2              çöğür     çöğür  Noun+A3sg+Pnon+Nom         23\n",
       "3            çöğürcü   çöğürcü  Noun+A3sg+Pnon+Nom          3\n",
       "4           çöğürden     çöğür  Noun+A3sg+Pnon+Abl          1\n",
       "...              ...       ...                 ...        ...\n",
       "1337893      zurnaya     zurna  Noun+A3sg+Pnon+Dat         23\n",
       "1337894     zurnayla     zurna  Noun+A3sg+Pnon+Ins        160\n",
       "1337895     zurnazen  zurnazen  Noun+A3sg+Pnon+Nom          4\n",
       "1337896  zurnazenler  zurnazen  Noun+A3pl+Pnon+Nom          2\n",
       "1337897         zurt      zurt                 dup         59\n",
       "\n",
       "[1337898 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#block 1st\n",
    "#export stem-word list\n",
    "#Resources\n",
    "# Description: 30,862 stems and their 200-dimensional frequencies (ordered list of the 200 dimensions is available at http://st2.zargan.com/public/resources/turkish/top_200_suffix_sequences_attached_to_nouns.zip\n",
    "# Column 1: stem, Columns 2-201: frequency of the relevant morphological form\n",
    "# Delimiter: tab, Encoding: UTF-8\n",
    "# Source: BOUN Corpus (Sak, H., Güngör, T., & Saraçlar, M. (2008). Turkish language resources: Morphological parser, morphological disambiguator and web corpus. In Advances in natural language processing (pp. 417-427). Springer Berlin Heidelberg.)\n",
    "# Copyright: Zargan Ltd.\n",
    "\n",
    "import pandas as pd\n",
    "#word_forms_stems_and_frequencies_full\n",
    "data = pd.read_csv('corpus.txt', sep=\"\\t\", header=None)\n",
    "data.columns=[\"derivates\",\"stems\",\"structure\",\"frequency\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stems_0 39843\n"
     ]
    }
   ],
   "source": [
    "#block 2nd\n",
    "#extract stems from the data\n",
    "stems_0=data[\"stems\"].unique().tolist()\n",
    "#number of stem list\n",
    "print(\"stems_0\",len(stems_0))\n",
    "#stems_0 39843 stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 3rd\n",
    "#method to show whether a word in stem list, or not\n",
    "def isin_stem_list(word,stem_list):\n",
    "    for stem in stem_list:\n",
    "        if stem==word:\n",
    "            return True\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stems_0 39843\n",
      "stems_1 39641\n",
      "stems_2 31838\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#block 4th\n",
    "print(\"stems_0\",len(stems_0))\n",
    "#cleaning the stem_list\n",
    "\n",
    "# Turkish language is an agglutinative language. So many \"derived forms\" can be created by using one stem and many suffixes.\n",
    "#These \"derived forms\" are semantically related to each other. \n",
    "#So the main goal for this procedure is to find the stem semantically involving more words.\n",
    "#This issue is discussed in  2nd question  in 1stStep_turkish_stems_ReadMe.txt\n",
    "\n",
    "\n",
    "stems_1=[]\n",
    "#Cleaning 1st step\n",
    "#remove one and two letters-stems (due to large size of semantic scope and thereby causing biased prediction)  \n",
    "\n",
    "for stem in stems_0:\n",
    "    if len(stem)>2:\n",
    "        stems_1.append(stem)\n",
    "        \n",
    "        \n",
    "#re-adding an exception ev (home)\n",
    "stems_1.append(\"ev\")\n",
    "stems_1.remove(\"evlek\")\n",
    "stems_1.remove(\"ypk\")\n",
    "\n",
    "print(\"stems_1\",len(stems_1))\n",
    "\n",
    "#Alternatively\n",
    "#remove two and three-letters-stems (due to large size of semantic scope and thereby causing biased prediction)\n",
    "#stems_1\n",
    "#for stem in stems_0:\n",
    "    #if len(stem)>3:\n",
    "        #stems_2.append(stem)\n",
    "        \n",
    "#Cleaning 2nd step\n",
    "#remove some \"derived form\" from stem list\n",
    "\n",
    "stems_2=[]\n",
    "\n",
    "for stem in stems_1:\n",
    "    \n",
    "    #for two letters suffixes\n",
    "    \n",
    "    #suffix -çi (and other variants -çı,-çu,-çü) like -er suffix in english\n",
    "    #suffix -ev (-home) (ex: dikim (sewing-tailoring) +ev(i) (-home)= dikimevi (sewing-tailoring workshop))\n",
    "    #suffix -li (and other variants -lı,-lu,-lü), like -ian or -er suffix in english (ex: dublin-li (dublin-er))\n",
    "    #suffix -la (and other variant -le) like bomba (bomb) and bomba-la-mak (to bomb)\n",
    "    #p21, p22,p3 and q2 boolean expressions for two-letters suffixes\n",
    "    p21=(stem.endswith(\"çı\") or stem.endswith(\"çi\") or stem.endswith(\"çu\") or stem.endswith(\"çü\") or stem.endswith(\"ev\") )\n",
    "    p22=(stem.endswith(\"lı\") or stem.endswith(\"li\") or stem.endswith(\"lu\") or stem.endswith(\"lü\"))\n",
    "    p23=(stem.endswith(\"la\") or stem.endswith(\"le\") )\n",
    "    \n",
    "    #stem without suffix -çi,-çı,-çu,-çü,-li,-lı,-lu, -lü, -la and -le  is meaningful namely is it in stem list ?    \n",
    "    q2=isin_stem_list(stem[:-2],stems_1)\n",
    "    \n",
    "    \n",
    "    #for three letters suffixes\n",
    "    \n",
    "    #suffix -lik (and other variants -lık,-luk,-lük) like -dom,-ness suffix (ex: kral (king) + -dom(-lık)=krallık (kingdom))\n",
    "    \n",
    "    p31=(stem.endswith(\"lik\") or stem.endswith(\"lık\") or stem.endswith(\"lük\") or stem.endswith(\"luk\"))\n",
    "    #suffix -len (and other variant -lan) making noun verb form like buz (ice) and buzlan-mak (to frost)\n",
    "    p32=(stem.endswith(\"len\") or stem.endswith(\"lan\"))\n",
    "    \n",
    "    #suffix -siz (and other variant -sız,-suz and -süz) -less in english ex: tat-sız (taste-less)\n",
    "    p33=(stem.endswith(\"siz\") or stem.endswith(\"sız\") or stem.endswith(\"suz\") or stem.endswith(\"süz\"))\n",
    "    \n",
    "    \n",
    "    #stem without suffix -lik,-lık,-luk,-lük,-lan,-len is meaningful namely is it in stem list ?  \n",
    "    q3=isin_stem_list(stem[:-3],stems_1)\n",
    "    \n",
    "    #for five letters suffixes\n",
    "    \n",
    "    #combination suffix -çi+-lik=-çilik (and other variants -çılık,-çuluk,-çülük)\n",
    "    p51=(stem.endswith(\"çilik\") or stem.endswith(\"çılık\") or stem.endswith(\"çülük\") or stem.endswith(\"çuluk\"))\n",
    "    #combination suffix -ci+-lik=-çilik (and other variants -cılık,-culuk,-cülük)\n",
    "    p52=(stem.endswith(\"cilik\") or stem.endswith(\"cılık\") or stem.endswith(\"cülük\") or stem.endswith(\"culuk\"))\n",
    "    #stem without suffix -lik,-lık,-luk,-lük,-lan,-len is meaningful namely is it in stem list ?  \n",
    "    q5=isin_stem_list(stem[:-5],stems_1)\n",
    "    \n",
    "    #combination suffix -siz+-lik=-sizlik (and other variants -sızlık,-suzluk,-süzlük)\n",
    "    #-siz and -lik  (-less and -ness in english respectively), ex: akıl-sız-lık (wit-less-ness)\n",
    "    p6=(stem.endswith(\"sizlik\") or stem.endswith(\"sızlık\") or stem.endswith(\"suzluk\") or stem.endswith(\"süzlük\"))\n",
    "    #stem without suffix -lik,-lık,-luk,-lük,-lan,-len is meaningful namely is it in stem list ?  \n",
    "    q6=isin_stem_list(stem[:-6],stems_1)\n",
    "    \n",
    "    #derived form detection\n",
    "    p=(p21 or p22 or p23 or p31 or p32 or p33 or p51 or p52 or p6) \n",
    "    \n",
    "    #stem without suffixes mentioned above is meaningful ?         \n",
    "    q=(q2 or q3 or q5 or q6)\n",
    "    \n",
    "    #abbrevations including \".\"  must be excluded\n",
    "    r=stem.find(\".\") !=-1\n",
    "    \n",
    "    \n",
    "    if not((p and q) or r ) :\n",
    "        stems_2.append(stem)\n",
    "      \n",
    "      \n",
    "#re-adding exceptions\n",
    "stems_2.append(\"ölçü\") \n",
    "stems_2.append(\"cemev\")\n",
    "stems_2.append(\"pertev\")\n",
    "stems_2.append(\"aşev\")\n",
    "stems_2.append(\"genelev\")\n",
    "stems_2.append(\"türev\")\n",
    "stems_2.append(\"huzurev\") \n",
    "stems_2.append(\"gözlük\")\n",
    "stems_2.append(\"evlen\")\n",
    "stems_2.append(\"evli\")\n",
    "\n",
    "#excluding some exceptions\n",
    "#stems_2.remove(\"simitis\")\n",
    "#stems_2.remove(\"kalemis\")\n",
    "#stems_2.remove(\"evç\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"stems_2\",len(stems_2))\n",
    "\n",
    "print(isin_stem_list(\"simitçilik\",stems_2))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#block 5th\n",
    "#test of cleaned stems\n",
    "print(isin_stem_list(\"ölçü\",stems_2))\n",
    "print(isin_stem_list(\"simitçi\",stems_1))\n",
    "print(isin_stem_list(\"simitçilik\",stems_2))\n",
    "print(isin_stem_list(\"simitçi\",stems_2))\n",
    "print(isin_stem_list(\"simit\",stems_2))\n",
    "print(isin_stem_list(\"simitçilik\",stems_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 5th\n",
    "\n",
    "#save stemps_2\n",
    "cleaned_stems=stems_2\n",
    "import pickle\n",
    "with open(\"cleaned_stems.txt\", \"wb\") as fp:\n",
    "       pickle.dump(cleaned_stems, fp)\n",
    "\n",
    "#load stemps\n",
    "#with open(\"cleaned_stems.txt\", \"rb\") as fp:\n",
    "    #cleaned_stems = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 6th\n",
    "\n",
    "#for tests\n",
    "# method to get stem from stem_list with maximum length involved by the word\n",
    "def get_max_stem_core(word,stem_list):\n",
    "    max_stem=word\n",
    "    #flag indicating whether stem, having more than one letters and maximum length, from cleaned stem list\n",
    "    #if flag=0, not found in stem_list, if flag=1, found in stem_list\n",
    "    flag=0\n",
    "    i=2\n",
    "    for stem in stem_list:\n",
    "        if (word[0:i]==stem[0:i] and word.find(stem) !=-1):\n",
    "        #if (word[0:i]==stem[0:i]) and len(stem)<len(word)):\n",
    "            max_stem=stem\n",
    "            flag=1\n",
    "            i=i+1\n",
    "        \n",
    "            \n",
    "            \n",
    "   \n",
    "        \n",
    "  \n",
    "          \n",
    "    return [max_stem,flag]\n",
    "\n",
    "#method to reconsruct derived form in \"Final-obstruent devoicing\", mentioned 3rd question  in 1stStep_turkish_stems_ReadMe.txt\n",
    "#by controlling  5 cases shown in letter list in the method by accessing index i\n",
    "def reconstruct(word,i):\n",
    "    original=[\"p\",\"ç\",\"t\",\"k\",\"k\"]\n",
    "    not_original=[\"b\",\"c\",\"d\",\"g\",\"ğ\"]\n",
    "    if (word.find(not_original[i])!=-1):\n",
    "        reversed_word=word[::-1]\n",
    "        k=reversed_word.index(not_original[i])\n",
    "        n=len(word)-k-1\n",
    "        reconstructed_list=list(word)\n",
    "        reconstructed_list[n]=original[i]\n",
    "        reconstructed_word=\"\".join(reconstructed_list)                \n",
    "    else:\n",
    "        reconstructed_word=word  \n",
    "    \n",
    "    \n",
    "        \n",
    "    return reconstructed_word\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#method to get stem with maximum length with using reconstructed derived form the word in case \"Final-obstruent devoicing\"\n",
    "def get_max_stem(word,stem_list):\n",
    "    result=get_max_stem_core(word,stem_list)\n",
    "    max_stem=result[0]\n",
    "    flag=result[1]\n",
    "    if flag==1:\n",
    "        #obivously no need reconstruction for the word\n",
    "        return max_stem\n",
    "    else:\n",
    "        i=0\n",
    "        #reconstruct word until find convenient stem\n",
    "        while(i<5 and flag==0):\n",
    "            reconst_word=reconstruct(word,i)\n",
    "            temp_result=get_max_stem_core(reconst_word,stem_list)\n",
    "            #whether found, or not ?\n",
    "            flag=temp_result[1]\n",
    "            i=i+1\n",
    "        if flag==1:\n",
    "            #max_stem of reconstructed word is found in stem_list\n",
    "            max_stem=temp_result[0]\n",
    "            \n",
    "        else:\n",
    "            # in spite of reconstructed forms of word, covenient stem could not be found\n",
    "            max_stem=word\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "   \n",
    "        \n",
    "  \n",
    "          \n",
    "    return max_stem\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "galatasaray\n",
      "simit\n",
      "ölçüm\n",
      "sultanahmet\n",
      "jübile\n",
      "köpek\n",
      "kit\n",
      "bomba\n",
      "evli\n",
      "mgönsmad m\n",
      "umu\n",
      "ağa\n",
      "örneğin\n",
      "şimşek\n",
      "umumiyet\n",
      "umumiyet\n",
      "kitap\n",
      "yıl\n",
      "kitap\n"
     ]
    }
   ],
   "source": [
    "#block 7th\n",
    "\n",
    "#test get_max_stems\n",
    "print(get_max_stem(\"galatasaraylılar\",cleaned_stems))\n",
    "print(get_max_stem(\"simitçiydim\",cleaned_stems))\n",
    "print(get_max_stem(\"ölçümüz\",cleaned_stems))\n",
    "print(get_max_stem(\"sultanahmetteyim\",cleaned_stems))\n",
    "print(get_max_stem(\"jübileniz\",cleaned_stems))\n",
    "print(get_max_stem(\"köpeğim\",cleaned_stems))\n",
    "print(get_max_stem(\"kitabım\",cleaned_stems))\n",
    "print(get_max_stem(\"bombaladılar\",cleaned_stems))\n",
    "print(get_max_stem(\"evliyiz\",cleaned_stems))\n",
    "print(get_max_stem(\"mgönsmad m\",cleaned_stems))\n",
    "print(get_max_stem(\"umudun\",cleaned_stems))\n",
    "print(get_max_stem(\"ağaç\",cleaned_stems))\n",
    "print(get_max_stem(\"örneğin\",cleaned_stems))\n",
    "print(get_max_stem(\"şimşeğin\",cleaned_stems))\n",
    "print(get_max_stem(\"umumiyetle\",cleaned_stems))\n",
    "print(get_max_stem(\"umumiyetle\",cleaned_stems))\n",
    "print(get_max_stem(\"kitapsızlar\",cleaned_stems))\n",
    "print(get_max_stem(\"yıllık\",cleaned_stems))\n",
    "print(get_max_stem(\"düşerek\",cleaned_stems))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "#block 8th\n",
    "#application for understanding suffixes\n",
    "\n",
    "#example 1\n",
    "#process for exclude stems ending with -la\n",
    "i=0\n",
    "for stem in stems_0:\n",
    "    #stem.endswith(\"la\") : stem ends with -la ?\n",
    "    #isin_stem_list(stem[:-2],stems_0): stem without -la is in stem_list, that is to stay, meaningful ?\n",
    "    if stem.endswith(\"la\") and isin_stem_list(stem[:-2],stems_0) :\n",
    "        print(stem)\n",
    "        i=i+1\n",
    "      \n",
    "\n",
    "    #number of these stems\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    }
   ],
   "source": [
    "#block 9th\n",
    "#example 2\n",
    "i=0\n",
    "for stem in stems_0:\n",
    "    #stem.endswith(\"lik\") : stem ends with -la ?\n",
    "    #isin_stem_list(stem[:-3],stems_0): stem without -la is in stem_list, that is to stay, meaningful ?\n",
    "    if stem.endswith(\"sız\") and isin_stem_list(stem[:-3],stems_0) :\n",
    "        print(stem)\n",
    "        i=i+1\n",
    "      \n",
    "    #number of these stems        \n",
    "print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çözümsüzlük\n",
      "ödünsüzlük\n",
      "ölçüsüzlük\n",
      "ölçütsüzlük\n",
      "ölümsüzlük\n",
      "örgütsüzlük\n",
      "alkolsüzlük\n",
      "dönüşsüzlük\n",
      "düşsüzlük\n",
      "gönülsüzlük\n",
      "görüşsüzlük\n",
      "görgüsüzlük\n",
      "güçsüzlük\n",
      "gürültüsüzlük\n",
      "golsüzlük\n",
      "hükümsüzlük\n",
      "hoşgörüsüzlük\n",
      "köksüzlük\n",
      "kültürsüzlük\n",
      "pürüzsüzlük\n",
      "süssüzlük\n",
      "sütsüzlük\n",
      "tahammülsüzlük\n",
      "usulsüzlük\n",
      "yönsüzlük\n",
      "yüzsüzlük\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "#block 10th\n",
    "#example 3\n",
    "#process for exclude stems ending with -çuluk\n",
    "i=0\n",
    "for stem in stems_0:\n",
    "    #stem.endswith(\"çuluk\") : stem ends with -la ?\n",
    "    #isin_stem_list(stem[:-5],stems_0): stem without -la is in stem_list, that is to stay, meaningful ?\n",
    "    if stem.endswith(\"çuluk\") and isin_stem_list(stem[:-5],stems_0) :\n",
    "        print(stem)\n",
    "        i=i+1\n",
    "      \n",
    "    #number of these stems        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çözümsüzlük\n",
      "ödünsüzlük\n",
      "ölçüsüzlük\n",
      "ölçütsüzlük\n",
      "ölümsüzlük\n",
      "örgütsüzlük\n",
      "alkolsüzlük\n",
      "dönüşsüzlük\n",
      "düşsüzlük\n",
      "gönülsüzlük\n",
      "görüşsüzlük\n",
      "görgüsüzlük\n",
      "güçsüzlük\n",
      "gürültüsüzlük\n",
      "golsüzlük\n",
      "hükümsüzlük\n",
      "hoşgörüsüzlük\n",
      "köksüzlük\n",
      "kültürsüzlük\n",
      "pürüzsüzlük\n",
      "süssüzlük\n",
      "sütsüzlük\n",
      "tahammülsüzlük\n",
      "usulsüzlük\n",
      "yönsüzlük\n",
      "yüzsüzlük\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "#block 11th\n",
    "#example 4\n",
    "#process for exclude stems ending with -süzlük\n",
    "i=0\n",
    "for stem in stems_0:\n",
    "    #stem.endswith(\"süzlük\") : stem ends with -la ?\n",
    "    #isin_stem_list(stem[:-6],stems_0): stem without -la is in stem_list, that is to stay, meaningful ?\n",
    "    if stem.endswith(\"süzlük\") and isin_stem_list(stem[:-6],stems_0) :\n",
    "        print(stem)\n",
    "        i=i+1\n",
    "      \n",
    "    #number of these stems        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
