{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 1st\n",
    "\n",
    "#import methods and datas in Predction Models with relevant objects\n",
    "%run ./Step3_Classifier_V10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 2nd\n",
    "#All models based on category scores of max_stems(mentioned previously) of preprocessed compounds (words) of doc\n",
    "#data is over-biased, namely, unbalanced. Models are conceived bearing in mind that fact.\n",
    "#Warning:\n",
    "#In case of duplication in computation of prediction, prediction is based on category with index lesser then others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 3rd\n",
    "#model1\n",
    "\n",
    "# Predict_Model1 based on maximum number of categories of max_stems in doc\n",
    "\n",
    "def predict_model1(doc,train_X,train_y):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not\n",
    "    if len(outcome)==0:\n",
    "        return \"No Prediction\"\n",
    "    #number of categories of max_stems in doc\n",
    "    category_counts=[0,0,0,0]\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "            #iterator for max_stems\n",
    "            for j in range(0,len(outcome)):\n",
    "                #counting for categories for each_max_stem\n",
    "                    if outcome[j][4]==main_categories[i]:\n",
    "                        category_counts[i]=category_counts[i]+1\n",
    "                        \n",
    "    #all categories of max_stems of doc is same, prediction is that category\n",
    "    if sum(category_counts)==max(category_counts):      \n",
    "            return main_categories[category_counts.index(max(category_counts))]\n",
    "    #if there is just two labels, then predicition is label having second largest count\n",
    "    else:\n",
    "        temp=category_counts.copy()\n",
    "        #set original max to 0, then second max can be obtained by max function\n",
    "        temp[temp.index(max(temp))]=0\n",
    "        return main_categories[temp.index(max(temp))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model1(doc):\n",
    "    return predict_model1(doc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 4th\n",
    "#model2 based on count of categories weighted by total of counts (of categories) in train set,\n",
    "#thereby effect of unbalanced categories is expected to be absorbed\n",
    "def predict_model2(doc,train_X,train_y):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not\n",
    "    if len(outcome)==0:\n",
    "        return \"No Prediction\"\n",
    "    #sum of counts for each categories\n",
    "    sum_category_counts=[0,0,0,0]\n",
    "    #count of categories weighted by total of counts (for each categories) in train set,\n",
    "    sum_category_probs=[0,0,0,0]\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #sum for counts of each max_stem categories\n",
    "            sum_category_counts[i]=sum_category_counts[i]+outcome[j][2][i]\n",
    "        # get sums weighted by counts (of categories) in train set   \n",
    "        sum_category_probs[i]=round(sum_category_counts[i]/train_counts[i],4)\n",
    "    \n",
    "    return main_categories[sum_category_probs.index(max(sum_category_probs))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model2(doc):\n",
    "    return predict_model2(doc,X_train,y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 5th\n",
    "#model3 based  mean of non-zero probablities of categories \n",
    "def predict_model3(doc,train_X,train_y):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not\n",
    "    if len(outcome)==0:\n",
    "        return \"No Prediction\"\n",
    "    #list  non-zero probabilities for each categories\n",
    "    non_zero_probs=[[],[],[],[]]\n",
    "    # means of non-zero probabilities for each categories\n",
    "    nz_probs_means=[0]*4\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #append non-zero probablities of max_stem to list of each categories\n",
    "            if outcome[j][3][i] >0:\n",
    "                non_zero_probs[i].append(outcome[j][3][i])\n",
    "        #control case divide-by-zero error in case of empty list        \n",
    "        if len(non_zero_probs[i]) !=0:\n",
    "            #set mean of probabilities for non-zero counts over categories\n",
    "            nz_probs_means[i]=round(sum(non_zero_probs[i])/len(non_zero_probs[i]),4)    \n",
    "            \n",
    "    # get category with maximum of means of probabilities         \n",
    "    return main_categories[nz_probs_means.index(max(nz_probs_means))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model3(doc):\n",
    "    return predict_model3(doc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 6th\n",
    "#model4 based  max of probablities of categories \n",
    "def predict_model4(doc,train_X,train_y):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not\n",
    "    if len(outcome)==0:\n",
    "        return \"No Prediction\"\n",
    "    #list of probabilities for each categories\n",
    "    probs=[[],[],[],[]]\n",
    "    # maximum of probabilities for each categories\n",
    "    max_prob_list=[0]*4\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #append probabilities of max_stems in doc\n",
    "            probs[i].append(outcome[j][3][i])\n",
    "        \n",
    "        #set maximum probabilities of max_stems for each categories\n",
    "        max_prob_list[i]=max(probs[i])   \n",
    "            \n",
    "    # get category with maximum probabilities in all max_stems in doc\n",
    "    return main_categories[max_prob_list.index(max(max_prob_list))]\n",
    "\n",
    "   \n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model4(doc):\n",
    "    return predict_model4(doc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 7th\n",
    "#model5 based on length of max_stems and count of categories weighted by total of counts (of categories) in train set\n",
    "#thereby effect of length of max_stems is added to the model, \n",
    "#it is assumed that longer word, greater effect on finding category\n",
    "#On the other hand with count of categories weighted by total of counts (of categories) in train set,\n",
    "#unbalanced case in data-set is not neglected\n",
    "def predict_model5(doc,train_X,train_y):\n",
    "    #analyze doc\n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not\n",
    "    if len(outcome)==0:\n",
    "        return \"No Prediction\"\n",
    "    #score (in direct proportion to both length and counts of max_stems) list \n",
    "    scores=[[],[],[],[]]\n",
    "    #list of maximum of score for each categories\n",
    "    max_score_list=[0]*4\n",
    "    #iterator for categories\n",
    "    for i in range(0,4):\n",
    "        #iterator for max_stems of doc\n",
    "        for j in range(0,len(outcome)):\n",
    "            #value1, length of max_stems\n",
    "            value1=outcome[j][1]\n",
    "            #value2, count of categories weighted by total of counts (of categories) in train set\n",
    "            value2=outcome[j][2][i]/train_counts[i]\n",
    "            #value3, a score in direct proportion to both length and counts of max_stems\n",
    "            value3=value1*value2\n",
    "            #append rounded value3\n",
    "            scores[i].append(round(value3,4))\n",
    "        \n",
    "        #set maximum score for each categories   \n",
    "        max_score_list[i]=max(scores[i])\n",
    "    \n",
    "      \n",
    "    # get category with maximum scores in all max_stems in doc\n",
    "    return main_categories[max_score_list.index(max(max_score_list))]\n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model5(doc):\n",
    "    return predict_model5(doc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 8th\n",
    "#Integrated_version of predict models 1-5\n",
    "def Integrated_model_ub(doc,train_X,train_y):\n",
    "    \n",
    "    outcome=analyze_doc(doc,train_X,train_y)\n",
    "    #check whether outcome is empty, or not\n",
    "    if len(outcome)==0:\n",
    "        return [\"No Prediction\"]*5\n",
    "    \n",
    "    #(model 1)\n",
    "    category_counts=[0,0,0,0]\n",
    "    \n",
    "    #(model 2)\n",
    "    sum_category_counts=[0,0,0,0]\n",
    "    sum_category_probs=[0,0,0,0]\n",
    "    \n",
    "     #(model 3)\n",
    "    non_zero_probs=[[],[],[],[]]\n",
    "    nz_probs_means=[0]*4\n",
    "    \n",
    "     #(model 4)\n",
    "    probs=[[],[],[],[]]\n",
    "    max_prob_list=[0]*4\n",
    "    \n",
    "    #(model 5)\n",
    "    scores=[[],[],[],[]]\n",
    "    max_score_list=[0]*4\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,4):\n",
    "            for j in range(0,len(outcome)):    \n",
    "                \n",
    "                 #(model 1)\n",
    "                if outcome[j][4]==main_categories[i]:\n",
    "                    category_counts[i]=category_counts[i]+1\n",
    "                        \n",
    "                #(model 2)\n",
    "                sum_category_counts[i]=sum_category_counts[i]+outcome[j][2][i]\n",
    "                \n",
    "                #(model 3)\n",
    "                if outcome[j][3][i] >0:\n",
    "                    non_zero_probs[i].append(outcome[j][3][i])\n",
    "                \n",
    "                #(model 4)\n",
    "                probs[i].append(outcome[j][3][i])\n",
    "                \n",
    "                 #(model 5)\n",
    "                value1=outcome[j][1]            \n",
    "                value2=outcome[j][2][i]/train_counts[i]\n",
    "                value3=value1*value2           \n",
    "                scores[i].append(round(value3,4))\n",
    "                \n",
    "            #(model 2)\n",
    "            sum_category_probs[i]=round(sum_category_counts[i]/train_counts[i],4)\n",
    "            \n",
    "            #(model 3)\n",
    "            if len(non_zero_probs[i]) !=0:\n",
    "                nz_probs_means[i]=round(sum(non_zero_probs[i])/len(non_zero_probs[i]),4)  \n",
    "                \n",
    "            #(model 4)\n",
    "            max_prob_list[i]=max(probs[i])\n",
    "            \n",
    "            #(model 5)\n",
    "            max_score_list[i]=max(scores[i])\n",
    "            \n",
    "            \n",
    "    #(model 1)\n",
    "    if sum(category_counts)==max(category_counts):\n",
    "        Predict1=main_categories[category_counts.index(max(category_counts))]\n",
    "    else:\n",
    "        temp=category_counts.copy()\n",
    "        temp[temp.index(max(temp))]=0\n",
    "        Predict1=main_categories[temp.index(max(temp))]\n",
    "        \n",
    "    #(model 2)\n",
    "    Predict2=main_categories[sum_category_probs.index(max(sum_category_probs))]\n",
    "    \n",
    "    #(model 3)\n",
    "    Predict3=main_categories[nz_probs_means.index(max(nz_probs_means))]\n",
    "    \n",
    "    #(model 4)\n",
    "    Predict4=main_categories[max_prob_list.index(max(max_prob_list))]   \n",
    "    \n",
    "    #(model 5)\n",
    "    Predict5=main_categories[max_score_list.index(max(max_score_list))]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return [Predict1,Predict2,Predict3,Predict4,Predict5]\n",
    "\n",
    "   \n",
    "\n",
    "#agent method\n",
    "#for  X_test.apply() function\n",
    "def agent_model_integrated_ub(doc):\n",
    "    return Integrated_model_ub(doc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5256\n",
      "label:\n",
      "DÜNYA\n",
      "______________________\n",
      "predictions: \n",
      "DÜNYA\n",
      "SANAT\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "DÜNYA\n",
      "run time for models runs-for-seperately (sec)\n",
      "3.8330440521240234\n",
      "['DÜNYA', 'SANAT', 'DÜNYA', 'DÜNYA', 'DÜNYA']\n",
      "run time for Integrated_model (sec) \n",
      "0.7720575332641602\n"
     ]
    }
   ],
   "source": [
    "#block 9th\n",
    "#test for predict models given above and run-time comparison\n",
    "\n",
    "import time\n",
    "import random\n",
    "n=random.randint(1,train_count)\n",
    "print(n)\n",
    "doc=X_train[X_train.index[n]]\n",
    "label=y_train[X_train.index[n]]\n",
    "print(\"label:\")\n",
    "print(label)\n",
    "print(\"______________________\")\n",
    "print(\"predictions: \")\n",
    "#start time\n",
    "start_time=time.time()\n",
    "print(predict_model1(doc,X_train,y_train))\n",
    "print(predict_model2(doc,X_train,y_train))\n",
    "print(predict_model3(doc,X_train,y_train))\n",
    "print(predict_model4(doc,X_train,y_train))\n",
    "print(predict_model5(doc,X_train,y_train))\n",
    "\n",
    "#show run-time\n",
    "print(\"run time for models runs-for-seperately (sec)\")\n",
    "print(time.time()-start_time)\n",
    "\n",
    "#start time\n",
    "start_time=time.time()\n",
    "print(Integrated_model_ub(doc,X_train,y_train))\n",
    "\n",
    "#show run-time\n",
    "print(\"run time for Integrated_model (sec) \")\n",
    "print(time.time()-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
